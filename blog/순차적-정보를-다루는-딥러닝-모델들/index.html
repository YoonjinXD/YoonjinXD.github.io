<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="순차적 데이터를 다루는 딥러닝 모델들" /><meta property="og:locale" content="en" /><meta name="description" content="Recurrent Neural Networks, 줄여서 RNN의 대표 모델들 공부." /><meta property="og:description" content="Recurrent Neural Networks, 줄여서 RNN의 대표 모델들 공부." /><link rel="canonical" href="https://yoonjinxd.github.io/blog/%EC%88%9C%EC%B0%A8%EC%A0%81-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EB%93%A4/" /><meta property="og:url" content="https://yoonjinxd.github.io/blog/%EC%88%9C%EC%B0%A8%EC%A0%81-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EB%93%A4/" /><meta property="og:site_name" content="Yoonjin" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-07-30T00:00:00+00:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="순차적 데이터를 다루는 딥러닝 모델들" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-04-13T15:35:11+00:00","datePublished":"2019-07-30T00:00:00+00:00","description":"Recurrent Neural Networks, 줄여서 RNN의 대표 모델들 공부.","headline":"순차적 데이터를 다루는 딥러닝 모델들","mainEntityOfPage":{"@type":"WebPage","@id":"https://yoonjinxd.github.io/blog/%EC%88%9C%EC%B0%A8%EC%A0%81-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EB%93%A4/"},"url":"https://yoonjinxd.github.io/blog/%EC%88%9C%EC%B0%A8%EC%A0%81-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EB%93%A4/"}</script><title>순차적 데이터를 다루는 딥러닝 모델들 | Yoonjin</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Yoonjin"><meta name="application-name" content="Yoonjin"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.20.1/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-topbar-visible="true"><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper" style="text-align: center;"><h1 class="site-title"> <a href="/">Yoonjin</a></h1><p class="site-subtitle fst-italic mb-0">Audio AI</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/blog/" class="nav-link"> <i class="fa-fw fas fa-pen"></i> <span>BLOG</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag"></i> <span>TAGS</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <a href="https://github.com/YoonjinXD" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="https://www.linkedin.com/in/yoon-jin-chung-03783016a/" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="https://scholar.google.com/citations?user=UXaiGH4AAAAJ&hl=en" aria-label="google-scholar" target="_blank" rel="noopener noreferrer" > <i class="fa fa-graduation-cap"></i> </a> <a href="https://twitter.com/" aria-label="twitter" target="_blank" rel="noopener noreferrer" > <i class="fab fa-twitter"></i> </a></div></aside><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>순차적 데이터를 다루는 딥러닝 모델들</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>순차적 데이터를 다루는 딥러닝 모델들</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1564444800" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 30, 2019 </em> </span> <span> Updated <em class="" data-ts="1713022511" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Apr 14, 2024 </em> </span><div class="d-flex justify-content-between"> <span> By <em> <a href="https://github.com/yoonjinxd">Yoonjin Chung</a> </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2506 words"> <em>13 min</em> read</span></div></div></div><div class="post-content"><p>Recurrent Neural Networks, 줄여서 RNN의 대표 모델들 공부.</p><hr /><h5 id="introduction"><span class="mr-2">Introduction</span><a href="#introduction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p>RNN은 기본적으로 순차적 정보를 가지는 sequential data(ex. time-series data) 를 효과적으로 학습하기 위해 고안된 모델이다. 데이터의 종류를 구분하는 방법은 여러가지가 있지만, 아주 간단하게는 many OR one 으로 구분할 수 있다.</p><p><a href="https://i.imgur.com/Q8zv6TQ.png" class="popup img-link "><img data-src="https://i.imgur.com/Q8zv6TQ.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>*[Figure 0] Sequential data and RNN</p><p><em>위와 같이 RNN이 풀 수 있는 문제는 다양하다</em></p><h5 id="short-history"><span class="mr-2">Short History</span><a href="#short-history" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h5><p>RNN 아이디어 자체는 1980년대 등장하여 근 30년간 조용히 연구되던 분야다. 기본 RNN을 계승하여 attention 기법, LSTM, GRU 등의 모델들이 차례로 등장하였고, 이 모델들의 성과는 그 당시 꽤 만족스러웠기에 Sequential data 하면 RNN을 통상적으로 사용해왔다. 특히 자연어 및 비디오/음성 데이터와 같이 순차적 성질을 가진 데이터의 경우 RNN 계열 모델을 사용하는 것이 당연했다.</p><blockquote><p>Then in the following years (2015–16) came <a href="https://arxiv.org/abs/1512.03385?source=post_page---------------------------">ResNet</a> and <a href="https://arxiv.org/abs/1502.03044?source=post_page---------------------------">Attention</a>. One could then better understand that LSTM were a clever bypass technique. Also attention showed that MLP network could be replaced by <em>averaging</em>networks influenced by a <em>context vector</em>.</p><p><em>Reference</em> - ‘The fall of RNN and LSTM’, 2018, Eugenio Culurciello</p></blockquote><p>2017년 12월에 ‘Attention is all you need’ 라는 제목의 논문이 게재되었다. 논문은 기존 RNN 기반 알고리즘을 완전히 탈피하고, sequential data를 처리할 수 있는 새로운 모델 - Transformer를 제안했다. 물론 그 이전에도 attention 기법을 기존 모델에 적용하려는 시도 및 성과는 분명 있었으나, RNN의 틀을 벗어나지는 못했었다. 논문은 그 상식을 깨고, 제목처럼 attention’만’ 써도 순차 정보를 처리하기에 충분하며 심지어 더 좋기까지 하다는 내용을 발표한 것이다. 뿐만 아니라 이들이 소개한 Transformer는 기존 SOTA 모델들을 월등한 차이로 이기며 많은 NLP task에서 좋은 점수를 냈다. 이 논문을 기점으로 NLP 분야의 연구 방향이 확 바뀌었다고 볼 수 있을 것 같은데, 이 Transformer 공부를 위해 기존 RNN 기법부터 차근차근 정리 해보려 한다.</p><h4 id="1-rnn"><span class="mr-2">1. RNN</span><a href="#1-rnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>RNN은 n번째에 대한 output #n 을 생성하기 위해, 그에 상응하는 input #n 과 추가적으로 n-1번째 hidden state #n-1 를 전달하여 문장의 순차적 특성을 활용 및 보존한다.</p><p><a href="https://miro.medium.com/max/700/1*NKhwsOYNUT5xU7Pyf6Znhg.png" class="popup img-link "><img data-src="https://miro.medium.com/max/700/1*NKhwsOYNUT5xU7Pyf6Znhg.png" alt="1563521630325" class="lazyload" data-proofer-ignore></a></p><p><em>[Figure 1.1] RNN basic architecture</em></p><p>위는 RNN의 기본 구조를 잘 표현한 그림. 동작 방식은 대략 Input data의 순서대로,</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>1. input x_n을 n번째 cell에 입력
2. input x_n &amp; hidden state_n-1 을 cell 가중치에 곱하여 예측 값인 output h_n 을 출력
3. hidden state_n 을 다음 n+1번째 cell에 전달
4. input x_n+1을 n+1번째 cell에 입력
5. ...반복... 입력 시퀀스가 끝날 때까지
</pre></table></code></div></div><p>보다시피 순차적인 input-output 방식에 hidden state라는 벡터가 추가되어 동작하는데, 이 hidden state 는 순차적으로 Input -&gt; Output 계산을 해나갈 때 차례차례 전달되어 다음 연산시 함께 계산된다. n번째 input에게 이전 input(0부터 n-1번째)들의 정보를 전달하기 위함이다.</p><ul><li>Forward</ul><p><a href="https://i.imgur.com/vrD0VO1.png" class="popup img-link "><img data-src="https://i.imgur.com/vrD0VO1.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>*[Figure 1.2] RNN Forwarding Example</p><p>Forwarding 하는 과정을 조금 더 자세히 보자. 위 그림은 ‘hell’ 이라는 순차문자열을 input으로 하였을 때, 다음에 나올 문자를 ‘o’ 라고 예측하는 예시이다. 첫번째 순서인 ‘h’ 를 첫번째 cell에 푸쉬하고 hidden layer의 연산을 통해 다음에 나올만한 문자를 확률 값으로 나타낸다. 보면 마지막 행인 ‘o’ 4.1로 가장 확률이 높지만 사실 답은 2번째 초록 글씨로 볼드처리된 ‘e’인 것을 알 수 있다. 그러니 초록글씨 행은 강화되고 빨간 글씨 행들은 약화되도록 학습시킬 것이다. 두번째 문자인 ‘e’도 같은 방식으로 연산된 후 ‘o’를 1.2의 확률로 가장 높게 예측했다. 틀렸다. 이번에도 첫번째 했던 것과 똑같은 방식으로 학습 시킬 것이다. 하지만 이번부터는 hidden layer가 동작하고 있음을 주목해야 한다. 이번에 예측된 ‘o’는 앞서 계산하였던 ‘h’에 대한 정보를 전달 받아 input 인 ‘e’ 와 함께 연산된 결과이다. 다음 cell은 다음 input인 ‘l’ 과, 전달 받은 과거의 정보(h, e)가 담긴 hidden state를 함께 연산하여 다음 문자를 예측한다. 세번째는 잘 맞췄다. 이제 마지막, 실제 정답인 ‘o’를 예측해야 하는 마지막 cell 에게 각각 상응하는 가중치와 연산된 hidden state, input을 입력 받아 다음에 나올 문자에 대한 probability를 계산한다. (+ 위 예시는 teacher forcing을 적용한 예시. 모델이 틀린 답을 냈지만 다음 cell의 input에 target char를 넣어주고 있음.)</p><ul><li><p>보통, 실제 input인 ‘hell’ 에 대해 진행한 세 번의 연산은 encoder라 하고, 마지막 실제 알고자 하는 결과에 대한 연산을 decoder라 한다. 이 예제는 many to one이기에 매우 간단해 보이는데, 만약 many to many 모델이면 실제 인풋이 끝나는 지점에서 hidden state에 가중치 W_hh를 곱해준다. 또한 decoder에서 input 대신 바로 이전 cell의 output을 input으로 사용한다.</p><p><a href="https://yoonjinxd.github.io/images/2019-07-30-순차적-정보를-다루는-딥러닝-모델들\1.jpg" class="popup img-link "><img data-src="https://yoonjinxd.github.io/images/2019-07-30-순차적-정보를-다루는-딥러닝-모델들\1.jpg" alt="img" class="lazyload" data-proofer-ignore></a></p><p>*[Figure 1.3] RNN many to many architecture</p></ul><h4 id="2-attention-mechanism"><span class="mr-2">2. Attention Mechanism</span><a href="#2-attention-mechanism" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>위와 같은 RNN 구조의 가장 큰 한계점은 바로 <strong>Long-Term dependency</strong> 문제다. Long-term dependency는 문장이 길어질수록 비교적 초반부에 입력받은 input에 대한 정보를 손실하게 되는 현상을 말하는데, RNN에서 이 문제를 해결하고자 고안된 메커니즘 중 하나로 attention이 있다.</p><p><a href="https://yoonjinxd.github.io/images/2019-07-30-순차적-정보를-다루는-딥러닝-모델들\2.jpg" class="popup img-link "><img data-src="https://yoonjinxd.github.io/images/2019-07-30-순차적-정보를-다루는-딥러닝-모델들\2.jpg" alt="img" class="lazyload" data-proofer-ignore></a></p><p>*[Figure 2.1] RNN with attention</p><blockquote><p>베이직한 RNN 모델은 Encoder가 먼저 순차적으로 문장을 읽어가며 하나의 hidden state 값을 전달해 나갔으나, 문장이 길어지면 비교전 초반부의 내용이 희미해지는 문제가 있다.</p><p>-&gt; 그렇다면, hidden state를 여러개 만들자!</p></blockquote><p>베이직한 RNN 모델에서는 hidden state가 모든 input data를 거친 후 디코더의 시작 cell에 전달되기 때문에 input data의 앞 내용을 많이 잊어버린 상태일 수 밖에 없었다. 그렇기에 각 input에 대한 hidden state를 따로 저장해놓고 그 순서에 맞는 decoder cell에 전달해주자는 아이디어가 나온 것 같다. 이 방법으로 성능이 개선 되었다고는 하나, 개인적으로는 이게 attention이라는 단어와는 잘 안 맞는다는 생각이 들기도 한다. attention이라면 뭔가 주목을 해야 하는데, 이건 주목이라기 보단 그냥 초반부의 정보를 저장해놓고 활용하는 트릭인 것 같기도 하고…(내가 잘 이해한 게 맞나?)</p><h4 id="3-lstmlong-short-term-memory"><span class="mr-2">3. LSTM(Long Short-term Memory)</span><a href="#3-lstmlong-short-term-memory" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>Long-term dependency를 극복하고자 한 또다른 시도는, hidden state 계산을 업그레이드 시킨 LSTM 이다. LSTM은 기존 RNN 구조를 기반으로 하되, 이제 hidden state는 무작정 합성곱만 하는 것이 아니라, 기억해야 할 정보와 잊어버려도 될 정보들을 따로 계산하여 최대한 input 데이터의 핵심만 남기려 한다.</p><p><a href="http://i.imgur.com/jKodJ1u.png" class="popup img-link "><img data-src="http://i.imgur.com/jKodJ1u.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>*[Figure 3.1 ~ 3.5] LSTM Architecture</p><p>전체 흐름은 기본 RNN과 동일하나, Cell state update는 크게 세가지 스텝으로 진행된다.</p><ul><li><p>Forward</p><p><strong>(1) Forget gate</strong></p><p>먼저 현재 Cell-state 값을 업데이트 하기 위해 forget gate와 input gate를 각각 따로 거친다.</p><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png" class="popup img-link "><img data-src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>forget gate의 수식은 위와 같다. 이전 Cell의 아웃풋(h_t-1)과 현재 인풋(x_t)를 forget layer의 Weight 및 bias 를 거쳐 시그모이드에 의해 0과 1 사이의 확률값으로 표현된다. 이렇게 표현된 값은 이전 아웃풋과 현재 인풋을 보고, 이전의 정보를 얼만큼 잊을 것인가? 를 정의한다고 볼 수 있다. 따라서 이 값은 이전 Cell state(C_t-1)과 연산한다.</p><p><strong>(2) Cell-state 업데이트</strong></p><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png" class="popup img-link "><img data-src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>이제 현재 Cell-state를 실질적으로 업데이트 한다. 먼저 이전 아웃풋과 현재 인풋의 가중치 연산에 따라 얼마나 정보를 업데이트 할 것인지 확률값으로 나타내고(i_t), 또 다른 가중치 연산을 tanh 하여 -1 ~ 1 의 값으로 표현한 현재 Cell state의 추정치(C_t)를 구한다. 수식이 이해하기 쉽다.</p><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png" class="popup img-link "><img data-src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>마지막으로 앞서 계산한 f_t 와 이전 Cell state 값을 연산하여 이전 정보를 어느 정도 담고, 현재 추정되는 Cell state의 값을 i_t를 통해 어느 정도 담아 현재 Cell-state값을 완성한다.</p><p><strong>(3) Output 도출</strong></p><p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png" class="popup img-link "><img data-src="http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>현재의 Cell state 를 구했다면 이제 아웃풋 값을 계산할 수 있다. 전과 비슷한 과정으로 아웃풋이 계산된다. (그림의 x 부호는 Hadamard product 연산)</p><li><p>matrix 연산부까지 구현한 코드</p><p>https://gist.github.com/karpathy/d4dee566867f8291f086</p></ul><h4 id="4-grugated-recurrent-unit"><span class="mr-2">4. GRU(Gated Recurrent Unit)</span><a href="#4-grugated-recurrent-unit" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p>LSTM의 발전된 형태로, 성능은 유지하면서 계산량을 확 줄인 셀 구조이다. 기존 forget, input, output gate를 update gate 와 reset gate로 변형하였다. 불필요한 계산을 줄여 보다 컴팩트해진 LSTM 모델이다.</p><p><a href="http://i.imgur.com/rehjrBZ.png" class="popup img-link "><img data-src="http://i.imgur.com/rehjrBZ.png" alt="img" class="lazyload" data-proofer-ignore></a></p><p>*[Figure 4.1] GRU architecture</p><p><em>Last Update: 2019/07/30</em></p><p><em>References</em></p><p>http://colah.github.io/posts/2015-08-Understanding-LSTMs/</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/reviews/'>reviews</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ai/" class="post-tag no-text-decoration" >AI</a> <a href="/tags/sequential/" class="post-tag no-text-decoration" >sequential</a> <a href="/tags/models/" class="post-tag no-text-decoration" >models</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.linkedin.com/in/yoon-jin-chung-03783016a/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/blog/%EC%88%9C%EC%B0%A8%EC%A0%81-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EB%93%A4/">순차적 데이터를 다루는 딥러닝 모델들</a><li><a href="/blog/AIKorea-2019-%EB%A6%AC%EB%B7%B0/">AI Korea 2019 리뷰</a><li><a href="/blog/2019-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EC%9C%88%ED%84%B0%EC%BD%94%EB%94%A9-%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4/">2019 프로그래머스 윈터 코딩 문제 풀이</a><li><a href="/blog/Audio-Based-Album-Cover-Generator/">Audio-based Album Cover Generator</a><li><a href="/blog/Music-Auto-Tagging/">Music Auto Tagging</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/generation/">generation</a> <a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/audio-text/">audio-text</a> <a class="post-tag" href="/tags/classification/">classification</a> <a class="post-tag" href="/tags/dsp/">DSP</a> <a class="post-tag" href="/tags/metric-learning/">metric-learning</a> <a class="post-tag" href="/tags/models/">models</a> <a class="post-tag" href="/tags/music-image/">music-image</a> <a class="post-tag" href="/tags/music-tag/">music-tag</a></div></div></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5"><div id="related-posts" class="mb-2 mb-sm-4"><h3 class="pt-2 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/blog/Audio-Based-Album-Cover-Generator/"><div class="card-body"> <em class="small" data-ts="1611446400" data-df="ll" > Jan 24, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Audio-based Album Cover Generator</h3><div class="text-muted small"><p> This project is based on 2021 Fall GCT634 at KAIST github link: https://github.com/YoonjinXD/Audio_Based_Album_Cover_Generator Making album cover images is a difficult task for many amateur mus...</p></div></div></a></div><div class="card"> <a href="/blog/Music-Auto-Tagging/"><div class="card-body"> <em class="small" data-ts="1637539200" data-df="ll" > Nov 22, 2021 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Music Auto Tagging</h3><div class="text-muted small"><p> This project is based on Fall 2021 GCT 634 at KAIST github link: https://github.com/YoonjinXD/Music-Auto-Tagging SUMMARY I implemented and performed related experiments to verify the improve...</p></div></div></a></div><div class="card"> <a href="/blog/Text-conditioned-Audio-Editing/"><div class="card-body"> <em class="small" data-ts="1677715200" data-df="ll" > Mar 2, 2023 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Text-conditioned Audio Editing</h3><div class="text-muted small"><p> 2022 Fall AI605 Final Project, Yoonjin Chung, Junwon Lee github link: https://github.com/YoonjinXD/Text-conditioned-Audio-Editing report: https://github.com/YoonjinXD/Text-conditioned-Audio-Editi...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"><div class="btn btn-outline-primary disabled" prompt="Older"><p>-</p></div><a href="/blog/AIKorea-2019-%EB%A6%AC%EB%B7%B0/" class="btn btn-outline-primary" prompt="Newer"><p>AI Korea 2019 리뷰</p></a></div></div></div></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/generation/">generation</a> <a class="post-tag" href="/tags/algorithm/">algorithm</a> <a class="post-tag" href="/tags/audio-text/">audio-text</a> <a class="post-tag" href="/tags/classification/">classification</a> <a class="post-tag" href="/tags/dsp/">DSP</a> <a class="post-tag" href="/tags/metric-learning/">metric-learning</a> <a class="post-tag" href="/tags/models/">models</a> <a class="post-tag" href="/tags/music-image/">music-image</a> <a class="post-tag" href="/tags/music-tag/">music-tag</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><footer><div class="container pl-lg-4 pr-lg-4"><div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/yoonjinxd">Yoonjin Chung</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0">Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></div></footer><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lazysizes@5.3.2/lazysizes.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-WC36HCMDDJ"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-WC36HCMDDJ'); }); </script>
