---
layout: post
title: URL 정리 노트
categories: Etc
tags: Etc
---
공부하며 스스로 참고하려고 만든 URL 정리 노트입니다.

공유 목적으로 만들던 것이 아니라 토픽이 한정되어 있고 정신 사나울 수 있습니다... :) 

Last Updated 2019/07/18 - Yoonjin Chung 

***

### 1.Topics 

**[General NN]**

Backpropagation 

https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b

Attention? Attention!

https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html

NasNet

https://medium.com/@sh.tsang/review-nasnet-neural-architecture-search-network-image-classification-23139ea0425d

Must-Read Papers on GANs

https://towardsdatascience.com/must-read-papers-on-gans-b665bbae3317

Scene Text 논문 모음

https://github.com/yflv-yanxia/scene_text



**[RNN]**

Illustration of RNN

http://jalammar.github.io/visual-interactive-guide-basics-neural-networks/

RNN & LSTM

https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/

LSTM (more details)

http://colah.github.io/posts/2015-08-Understanding-LSTMs/

Illustrated LSTM

http://arunmallya.github.io/writeups/nn/lstm/index.html#/

The fall of RNN/LSTM 

https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0

Transformer

https://pozalabs.github.io/transformer/

http://jalammar.github.io/illustrated-transformer/

Skip-Thoughts

http://sanyam5.github.io/my-thoughts-on-skip-thoughts/

Sparse Transformer

https://openai.com/blog/sparse-transformer/

Transformer Details Not Described in The Paper

https://tunz.kr/post/4



**[CNN]**

Overview of CNN in pytorch

https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/

CNN Architecture 역사? 정리

https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5

EfficientNet

https://github.com/lukemelas/EfficientNet-PyTorch

https://medium.com/@nainaakash012/efficientnet-rethinking-model-scaling-for-convolutional-neural-networks-92941c5bfb95



**[NLP]**

BERT word embedding tutorial

https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/ㅑ*

Image Captioning(From translation to Attention)

https://medium.com/mlreview/multi-modal-methods-image-captioning-from-translation-to-attention-895b6444256e



**[Math]**

Activation Function

https://medium.com/swlh/only-numpy-why-we-need-activation-function-non-linearity-in-deep-neural-network-with-529e928820bc

SVD, PCA, LSA(잠재의미분석) 

https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/06/pcasvdlsa/

SVD 디테일

https://darkpgmr.tistory.com/106

Mathematical Approach

https://medium.com/analytics-vidhya/demystifying-neural-networks-a-mathematical-approach-part-1-4e10bed61400



***

### 2.읽어보면 좋을 

##### -천상계 블로그 

Christopher Manning 교수님 NLP 연구실 논문 모음(언어학 관련 논문)

https://nlp.stanford.edu/manning/dissertations/

ratsgo 님 블로그

https://ratsgo.github.io/blog/categories/

변성윤 님 블로그 (어쩐지 오늘은)

https://zzsza.github.io/tag/data-dl/

CS231n 노트

http://cs231n.github.io/

포자랩스 블로그

https://pozalabs.github.io/blog/

서재덕 님 미디엄

https://medium.com/@SeoJaeDuk

다크 프로그래머님 블로그 (수학)

[https://darkpgmr.tistory.com/](https://darkpgmr.tistory.com/category/수학 이야기)

갓파띠 블로그

http://karpathy.github.io/



##### -책

How not to be Wrong: The hidden Maths of Everyday Life

Introduction to Convex optimization (Nesterov.)


##### -논문 

**[General NN]**

Randomly Wired NN for Image recognition (!)

https://arxiv.org/pdf/1904.01569.pdf

스탠포드대 CV 연구실 논문 리스트

http://vision.stanford.edu/publications.html

Attention is all you need

https://arxiv.org/abs/1706.03762



**[NLP]**

Better Language Models  

https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf

XLNet

https://arxiv.org/pdf/1906.08237.pdf

Convolutional Seq2seq Learning

https://arxiv.org/pdf/1705.03122.pdf

Sparse Transformer

https://arxiv.org/pdf/1904.10509.pdf

Recent Trends in Deep Learning Based NLP (NLP 최근동향 총정리. 짱좋음)

https://arxiv.org/pdf/1708.02709.pdf

Transformer-XL

https://arxiv.org/pdf/1901.02860.pdf



**[Image Captioning]**

Show and Tell

Show, attend and Tell

http://proceedings.mlr.press/v37/xuc15.pdf



**[RNN]**

Attention is all you need
[Image Captioning SOCKEYE Project](https://arxiv.org/pdf/1810.04101.pdf)



**[CV]**

ImageNet

YOLO

EfficientNet

MATraseE -> VRD. 어디까지 복잡해질 수 있나, 그래도 좋은 결과



***

### 3.코드 

(MY)간단한 2-layer model (matrix 연산부 구현)

https://github.com/YoonjinXD/NN_toymodel

Skip-Thoughts

https://github.com/sanyam5/skip-thoughts

Transformer

https://github.com/tunz/transformer-pytorch

MXNet: Sockeye Project (seq2seq 프레임워크)

https://github.com/awslabs/sockeye

Tensor2Tensor

https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/models

NLP Tutorial

https://github.com/graykode/nlp-tutorial?source=post_page---------------------------

BERT 모델 (카카오 브레인 이동현님)

https://github.com/dhlee347/pytorchic-bert/blob/master/models.py#L123-L133